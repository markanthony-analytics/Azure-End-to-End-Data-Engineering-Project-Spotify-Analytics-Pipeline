# Azure-End-to-End-Data-Engineering-Project-Spotify-Analytics-Pipeline

## ğŸ“Œ Project Overview

This project demonstrates a full end-to-end modern data engineering pipeline on Azure using Spotify streaming data.
The goal is to ingest raw files from Azure Storage, perform data cleaning & transformations using Spark in Azure Databricks, and create curated analytics tables for downstream reporting & trend insights.

The solution mirrors how data engineering pipelines are built in real-world cloud environmentsâ€”scalable, fault-tolerant, and analytics-ready.

## ğŸ¯ Project Objectives
| Goal                                                          | Description                                                      |
| ------------------------------------------------------------- | ---------------------------------------------------------------- |
| âœ” Ingest raw Spotify dataset into Azure Data Lake (ADLS Gen2) | CSV/JSON ingestion using structured landing zones                |
| âœ” Build scalable ETL pipelines with PySpark on Databricks     | Schema enforcement, transformations, partitioning, Delta support |
| âœ” Store processed data in Delta Lake format                   | Time travel enabled, optimized for analytics workloads           |
| âœ” Analyze Spotify artist, album & track trends                | Most streamed artists, tempo patterns, popularity metrics        |
| âœ” Enable BI consumption (Power BI)                            | Curated layer available for dashboarding                         |

## ğŸ—ï¸ Project Architecture
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Spotify Source Dataset      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                     Raw Zone (Bronze)
              Azure Data Lake Storage Gen2
                                â”‚
                                â–¼
                   Databricks ETL Processing
            PySpark Cleaning, Joins, Validation
                                â”‚
                                â–¼
                 Refined Zone (Silver)
              Delta Lake Structured Tables
                                â”‚
                                â–¼
                 Curated Zone (Gold)
         Analytics-Optimized Fact + Dimension Tables
                                â”‚
                                â–¼
                        Power BI Reporting
              Dashboards & Trend Visual Insights
## ğŸ§© Solution Breakdown
| Layer             | Technology                    | Output                                |
| ----------------- | ----------------------------- | ------------------------------------- |
| **Storage**       | ADLS Gen2                     | Raw â†’ Refined â†’ Curated               |
| **ETL Compute**   | Azure Databricks + PySpark    | Transformations, cleansing, merges    |
| **Lake Format**   | Delta Lake                    | ACID, schema enforcement, time travel |
| **Orchestration** | (Optional) Azure Data Factory | Scheduling & monitoring               |
| **Consumption**   | Power BI / Databricks SQL     | Data insights, dashboards             |

## ğŸ“‚ Repository Structure
spotify_azure_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Initial uploaded data (CSV/JSON)
â”‚   â”œâ”€â”€ refined/         # Cleaned + structured Delta tables
â”‚   â””â”€â”€ curated/         # Analysis-ready datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_ingestion_raw.ipynb
â”‚   â”œâ”€â”€ 02_transformation_refined.ipynb
â”‚   â””â”€â”€ 03_curated_tables.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/           # Reusable helper functions (schema, IO)
â”‚   â”œâ”€â”€ pipeline_raw.py
â”‚   â”œâ”€â”€ pipeline_refined.py
â”‚   â””â”€â”€ pipeline_curated.py
â”‚
â””â”€â”€ README.md

## ğŸ”§ Key Features
| Feature                                       | Description                                       |
| --------------------------------------------- | ------------------------------------------------- |
| ğŸš€ Auto-load files into ADLS using Databricks | scalable ingestion patterns                       |
| ğŸ§ª Data validation + schema enforcement       | clean, consistent datasets                        |
| ğŸ“Š Curated fact tables for BI                 | tracks, artists, popularity metrics               |
| âš¡ Delta optimization                          | Z-ORDER, Caching, Auto-Optimize                   |
| ğŸ“‰ Power BI report layer                      | ranking charts, popularity trends, tempo analysis |

## ğŸ§ª Sample Transformation (PySpark)
from pyspark.sql.functions import col, lower, to_date

df_cleaned = (
    df_raw
    .withColumn("track_name", lower(col("track_name")))
    .withColumn("release_date", to_date(col("release_date"), "yyyy-MM-dd"))
    .filter(col("popularity") > 40)
)

## ğŸ“Š Sample Insights Generated
| Metric                   | Result               |
| ------------------------ | -------------------- |
| ğŸ§ Most streamed artist  | Drake                |
| ğŸ”¥ Most popular genre    | Hip-Hop / Pop Fusion |
| â± Avg track duration     | ~3m 10s              |
| ğŸ“ˆ Strongest correlation | Tempo vs Popularity  |

## ğŸ Conclusion

This repository provides a realistic, industry-standard cloud data pipeline for Spotify analytics using Azure.
It showcases storage, ETL processing, Delta Lake architecture & analytical consumptionâ€”just like enterprise implementations.
